{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/github/toby-htx/ONNX-Sharing-Session/blob/main/Demo2_HardwareAccess.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtJu3NrGD4UG"
      },
      "source": [
        "# **Demo 2: Hardware Access (ONNX Runtime)**\n",
        "\n",
        "**Tensorflow -> ONNX**\n",
        "\n",
        "In this demo, we are going to convert a model written in the Tensorflow framework to ONNX format and run it with ONNX Runtime. Specifically, we will convert a Tensorflow BiLSTM model that takes in Google's Word2Vec embeddings as input. This model had been used for the Fine Grained Sentiment Analysis workstream.\n",
        "\n",
        "You will need to change the **Runtime** to have a **GPU hardware accelerator**, then select '**Run All**'.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx_6wppBEd_A"
      },
      "source": [
        "##Secton 1: Tensorflow Model##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlBybC6XEak_"
      },
      "source": [
        "1) We need to **import the Word2Vec embeddings**. This will take around **20 minutes** as it is huge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLVcn0I-qh45",
        "outputId": "c26aa6c9-c8bb-4d30-974e-3a1bf3e5ed5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v = api.load(\"word2vec-google-news-300\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvoAgd0VD3cG"
      },
      "source": [
        "2) Import the dataset and preprocess it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPddvM_iPwI-",
        "outputId": "fa0f79c3-fb51-4d16-e9b7-fe7cf1bab33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Onnx-Sharing-Session'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n",
            "/bin/bash: line 0: cd: Data: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/toby-htx/Onnx-Sharing-Session.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JJka2ldGqvl5",
        "outputId": "af7a91aa-b14e-4980-a53a-c3ea66e176e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Statement</th>\n",
              "      <th>preprocessedStatement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fear</td>\n",
              "      <td>When I was left alone at home one night by my ...</td>\n",
              "      <td>When I was left alone at home one night by my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fear</td>\n",
              "      <td>When I was a child I was afraid of big dogs. O...</td>\n",
              "      <td>When I was a child I was afraid of big dogs  O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fear</td>\n",
              "      <td>When I forgot the lines of the play during an ...</td>\n",
              "      <td>When I forgot the lines of the play during an ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joy</td>\n",
              "      <td>The day I learnt that I had been admitted to t...</td>\n",
              "      <td>The day I learnt that I had been admitted to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>joy</td>\n",
              "      <td>When I was a student at the Institute doing my...</td>\n",
              "      <td>When I was a student at the Institute doing my...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Emotion  ...                              preprocessedStatement\n",
              "0    fear  ...  When I was left alone at home one night by my ...\n",
              "1    fear  ...  When I was a child I was afraid of big dogs  O...\n",
              "2    fear  ...  When I forgot the lines of the play during an ...\n",
              "3     joy  ...  The day I learnt that I had been admitted to t...\n",
              "4     joy  ...  When I was a student at the Institute doing my...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Bidirectional, LayerNormalization, LSTM, Dropout, BatchNormalization, Input, GlobalMaxPool1D, GlobalAveragePooling1D, concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "def process_text(document):\n",
        "     \n",
        "    # Remove extra white space from text\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "         \n",
        "    # Remove all the special characters from text\n",
        "    document = re.sub(r'\\W', ' ', str(document))\n",
        " \n",
        "    return document\n",
        "\n",
        "df = pd.read_csv('./Onnx-Sharing-Session/Data/Isear(Fear&Joy).csv')\n",
        "df = df[['Emotion','Statement']]\n",
        "df['preprocessedStatement'] = df.Statement.apply(process_text)\n",
        "display(df.head())\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'Emotion'. \n",
        "df['Emotion'] = le.fit_transform(df['Emotion']) \n",
        "y = df.pop('Emotion')\n",
        "y_new = tf.keras.utils.to_categorical(y, num_classes=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6mi6rqfE5tk"
      },
      "source": [
        "3) Like in the PyTorch model, we have to build the **Vocab** and **embedding matrix**, but in the **Tensorflow** way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ8hVVa6q_iy"
      },
      "outputs": [],
      "source": [
        "max_length = df.preprocessedStatement.apply(lambda x: len(x.split())).max()\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(df['preprocessedStatement'] )\n",
        "vocab_size = len(t.word_index) + 1\n",
        "encoded_text = t.texts_to_sequences(df['preprocessedStatement'] )\n",
        "X = pad_sequences(encoded_text, maxlen=max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uegRrY4ZrDVj"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "    try:\n",
        "      embedding_vector = w2v[word]\n",
        "    except KeyError:\n",
        "      pass\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhqSzjo3FR6M"
      },
      "source": [
        "4) Split the data into training, validation, and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1U4LQ2_rOXU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y_new, test_size=0.05, stratify=y)\n",
        "\n",
        "x_val = x_train[:100]\n",
        "y_val = y_train[:100]\n",
        "x_train = x_train[100:]\n",
        "y_train = y_train[100:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvAd-VcoFYBo"
      },
      "source": [
        "5) Prepare the BiLSTM model architecture. \n",
        "The model architecture was inspired by that used in *Z. Hameed and B. Garcia-Zapirain, \"Sentiment classification using a single-layered BiLSTM model\", IEEE Access, vol. 8, pp. 73992-74001, 2020.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abk-Mn0MrRWS",
        "outputId": "634f15d9-72f3-4085-ff7b-7384aaa4a589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 122)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 122, 300)     1337400     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 122, 64)      85248       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 64)           0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 64)           0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 128)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 64)           8256        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            130         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,431,034\n",
            "Trainable params: 93,634\n",
            "Non-trainable params: 1,337,400\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_layer = Input(shape=(max_length), )\n",
        "x = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "x_a = GlobalMaxPool1D()(x)\n",
        "x_b = GlobalAveragePooling1D()(x)\n",
        "x = concatenate([x_a,x_b])\n",
        "x = Dense(64, activation=\"relu\")(x)\n",
        "x = Dense(2, activation='softmax')(x)\n",
        "model_w2v_tf = Model(inputs=input_layer, outputs=x)\n",
        "model_w2v_tf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_w2v_tf.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuVmLpTNFjs1"
      },
      "source": [
        "6) Train the model. Note that model performance will not be ideal as we are trying to train it as fast as we can, hence the number of epochs is only 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT2dslX-rfGI",
        "outputId": "1e356ed2-12e5-48fd-ef11-caa3f07555c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 12s 60ms/step - loss: 0.5055 - accuracy: 0.7631 - val_loss: 0.2490 - val_accuracy: 0.8900\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbfc053d550>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_w2v_tf.fit(x_train, y_train, epochs = 1, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-MTY8jRGJp3"
      },
      "source": [
        "7) See how long it takes for the Tensorflow model to infer as well as its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVNBnixOrpL2",
        "outputId": "4f26efa7-222c-4f8a-9d9b-fe124fbf994f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken by TensorFlow model:  0.8981485366821289\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "y_pred = model_w2v_tf.predict(x_test)\n",
        "\n",
        "print(\"Time taken by TensorFlow model: \", time.time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eOfNnm9EbdY"
      },
      "outputs": [],
      "source": [
        "y_pred_clean = np.argmax(y_pred, 1)\n",
        "y_test_clean = np.argmax(y_test, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDiErZbaEdU-",
        "outputId": "911475be-bd09-4ac1-85e5-40caf86b6609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.78      0.86        54\n",
            "           1       0.82      0.96      0.88        55\n",
            "\n",
            "    accuracy                           0.87       109\n",
            "   macro avg       0.88      0.87      0.87       109\n",
            "weighted avg       0.88      0.87      0.87       109\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test_clean, y_pred_clean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93hQFNlCr8Iq",
        "outputId": "510f0095-b6dc-4643-a731-60e98b50533a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_w2v_tf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_w2v_tf/assets\n"
          ]
        }
      ],
      "source": [
        "model_w2v_tf.save('model_w2v_tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y90TPeHEGgb1"
      },
      "source": [
        "8) Download the required packages to use **ONNX** and **ONNX Runtime**. Note that specific Tensorflow versions are needed. This is a disadvantage of using ONNX: **you need to make sure the versions between ONNX and the DL frameworks are compatible**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BGcBuNeCCxHi",
        "outputId": "62da178f-3742-4df7-df29-35eb817c8979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 16 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.6.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, keras-nightly, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.41.0\n",
            "    Uninstalling grpcio-1.41.0:\n",
            "      Successfully uninstalled grpcio-1.41.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "Successfully installed grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 tensorflow-2.5.0 tensorflow-estimator-2.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "grpc",
                  "keras",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow==2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkPAEyJn5R4h",
        "outputId": "f6421481-54b3-477a-8abe-4d8020183189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.9.2-py3-none-any.whl (430 kB)\n",
            "\u001b[K     |████████████████████████████████| 430 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.19.5)\n",
            "Collecting onnx>=1.4.1\n",
            "  Downloading onnx-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3 MB 35.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12 in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.4.1->tf2onnx) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.4.1->tf2onnx) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx) (2021.5.30)\n",
            "Installing collected packages: onnx, tf2onnx, onnxruntime\n",
            "Successfully installed onnx-1.10.1 onnxruntime-1.9.0 tf2onnx-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tf2onnx onnxruntime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7wuTDULG378"
      },
      "source": [
        "9) Convert the **Tensorflow** model into an **ONNX** model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWrxRjIZr_AO",
        "outputId": "6618f878-53f2-44a3-c6bd-da42f58218b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-10-22 13:22:11.300393: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2021-10-22 13:22:13.891276: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-10-22 13:22:13.902155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:13.902993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:13.903037: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-10-22 13:22:13.927375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-10-22 13:22:13.927447: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-10-22 13:22:13.941375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-10-22 13:22:13.947736: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-10-22 13:22:14.026854: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
            "2021-10-22 13:22:14.042175: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-10-22 13:22:14.047759: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-10-22 13:22:14.047911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.048738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.049455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:14.050676: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-10-22 13:22:14.050969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.051756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:14.051868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.052647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.053353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:14.053418: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-10-22 13:22:14.588712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:14.588783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:14.588807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:14.588997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.589835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.590647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:14.591390: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-10-22 13:22:14.591458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-22 13:22:14,592 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2021-10-22 13:22:19,883 - INFO - Signatures found in model: [serving_default].\n",
            "2021-10-22 13:22:19,883 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2021-10-22 13:22:19,883 - INFO - Output names: ['dense_1']\n",
            "2021-10-22 13:22:19.890344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:19.891213: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2021-10-22 13:22:19.891434: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
            "2021-10-22 13:22:19.891839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:19.892646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:19.892753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:19.893561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:19.894277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:19.894352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:19.894376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:19.894396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:19.894521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:19.895361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:19.896183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-22 13:22:19.896587: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n",
            "2021-10-22 13:22:19.924024: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
            "  function_optimizer: Graph size after: 232 nodes (217), 277 edges (262), time = 10.248ms.\n",
            "  function_optimizer: Graph size after: 232 nodes (0), 277 edges (0), time = 4.203ms.\n",
            "Optimization results for grappler item: __inference_while_cond_8519_7889\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.009ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
            "Optimization results for grappler item: __inference_while_body_8520_3465\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.007ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
            "Optimization results for grappler item: __inference_while_body_8087_17350\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
            "Optimization results for grappler item: __inference_while_cond_8086_13181\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
            "\n",
            "2021-10-22 13:22:20.174140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.174960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:20.175071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.175840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.176616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:20.176685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:20.176711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:20.176731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:20.176859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.177633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.178370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "2021-10-22 13:22:20,223 - WARNING - From /usr/local/lib/python3.7/dist-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "2021-10-22 13:22:20.230514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.231636: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2021-10-22 13:22:20.231777: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
            "2021-10-22 13:22:20.232306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.233035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:20.233180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.233929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.234681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:20.234737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:20.234760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:20.234782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:20.234908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.235696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.236479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-22 13:22:20.288671: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
            "  constant_folding: Graph size after: 122 nodes (-27), 147 edges (-33), time = 15.868ms.\n",
            "  function_optimizer: Graph size after: 122 nodes (0), 147 edges (0), time = 4.947ms.\n",
            "  constant_folding: Graph size after: 122 nodes (0), 147 edges (0), time = 5.651ms.\n",
            "  function_optimizer: Graph size after: 122 nodes (0), 147 edges (0), time = 4.928ms.\n",
            "Optimization results for grappler item: __inference_while_cond_8519_7889\n",
            "  constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.454ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.017ms.\n",
            "  constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.177ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.011ms.\n",
            "Optimization results for grappler item: __inference_while_body_8520_3465\n",
            "  constant_folding: Graph size after: 50 nodes (0), 50 edges (0), time = 0.92ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.025ms.\n",
            "  constant_folding: Graph size after: 50 nodes (0), 50 edges (0), time = 0.607ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.024ms.\n",
            "Optimization results for grappler item: __inference_while_body_8087_17350\n",
            "  constant_folding: Graph size after: 50 nodes (0), 50 edges (0), time = 0.837ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.027ms.\n",
            "  constant_folding: Graph size after: 50 nodes (0), 50 edges (0), time = 0.673ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.026ms.\n",
            "Optimization results for grappler item: __inference_while_cond_8086_13181\n",
            "  constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.361ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.013ms.\n",
            "  constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.175ms.\n",
            "  function_optimizer: function_optimizer did nothing. time = 0.011ms.\n",
            "\n",
            "2021-10-22 13:22:20,396 - INFO - Using tensorflow=2.5.0, onnx=1.10.1, tf2onnx=1.9.2/0f28b7\n",
            "2021-10-22 13:22:20,397 - INFO - Using opset <onnx, 10>\n",
            "2021-10-22 13:22:20,766 - INFO - Computed 0 values for constant folding\n",
            "2021-10-22 13:22:20,776 - INFO - Computed 0 values for constant folding\n",
            "2021-10-22 13:22:20,780 - INFO - Computed 0 values for constant folding\n",
            "2021-10-22 13:22:20,784 - INFO - Computed 0 values for constant folding\n",
            "2021-10-22 13:22:20.987651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.988612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:20.988742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.989555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.990288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:20.990347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:20.990372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:20.990392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:20.990557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.991352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:20.992064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-22 13:22:21.005518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.006291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:21.006389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.007163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.007823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:21.007868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:21.007892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:21.007912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:21.008030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.008781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.009474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-22 13:22:21.016777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.017534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:21.017635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.018349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.019022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:21.019063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:21.019114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:21.019138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:21.019283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.020015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.020752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-22 13:22:21.030915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.031743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2021-10-22 13:22:21.031847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.032591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.033420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-10-22 13:22:21.033470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-10-22 13:22:21.033501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-10-22 13:22:21.033523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-10-22 13:22:21.033671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.034425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-22 13:22:21.035149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10512 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2021-10-22 13:22:21,039 - INFO - Computed 2 values for constant folding\n",
            "2021-10-22 13:22:21,315 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/model/bidirectional/forward_lstm/PartitionedCall/strided_slice\n",
            "2021-10-22 13:22:21,316 - INFO - folding node using tf type=StridedSlice, name=StatefulPartitionedCall/model/bidirectional/backward_lstm/PartitionedCall/strided_slice\n",
            "2021-10-22 13:22:21,481 - INFO - Optimizing ONNX model\n",
            "2021-10-22 13:22:22,269 - INFO - After optimization: Cast -8 (15->7), Concat -3 (6->3), Const -41 (62->21), ConstantOfShape -3 (4->1), Identity -65 (67->2), Less -1 (4->3), Placeholder -2 (21->19), Shape -2 (6->4), Slice -1 (2->1), Squeeze -2 (2->0), Transpose -3 (6->3), Unsqueeze -8 (8->0)\n",
            "2021-10-22 13:22:22,285 - INFO - \n",
            "2021-10-22 13:22:22,286 - INFO - Successfully converted TensorFlow model model_w2v_tf to ONNX\n",
            "2021-10-22 13:22:22,286 - INFO - Model inputs: ['input_1']\n",
            "2021-10-22 13:22:22,286 - INFO - Model outputs: ['dense_1']\n",
            "2021-10-22 13:22:22,286 - INFO - ONNX model is saved at model.onnx\n"
          ]
        }
      ],
      "source": [
        "!python -m tf2onnx.convert --saved-model 'model_w2v_tf' --opset 9 --output model.onnx "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruVOWOttHFeJ"
      },
      "source": [
        "##Secton 2: ONNX Model##\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WPqbjxiHLBM"
      },
      "source": [
        "10) Load the ONNX Model and compare its **inference speed** and **performance** with the Tensorflow model's. You should see that the **ONNX model is faster** while having the **same performance as the Tensorflow model**. This is because ONNX Runtime automatically optimises the use of the GPU in Google Colab to run your ONNX model, whereas the Tensorflow model is not yet transformed and optimised for inference on GPU.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXY5rBFz-9IS"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "onnx_model = onnx.load(\"model.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s57f6DFS_H62",
        "outputId": "9bf27031-aa91-49f6-d17f-abf9bd41fa49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken by ONNX model:  0.18747282028198242\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as rt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "model = ('model.onnx')\n",
        "start_time = time.time()\n",
        "session = rt.InferenceSession(model)\n",
        "input_name = session.get_inputs()[0].name\n",
        "label_name = session.get_outputs()[0].name\n",
        "onnx_predictions = session.run([label_name], {input_name: x_test.astype(np.float32)})[0]\n",
        "print(\"Time taken by ONNX model: \", time.time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWTzSY7mCb5Y"
      },
      "outputs": [],
      "source": [
        "onnx_pred_clean = np.argmax(onnx_predictions, 1)\n",
        "y_test_clean = np.argmax(y_test, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIg0W2_7_gjT",
        "outputId": "06b892b7-5cf0-44b5-f005-8edadcf55d6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.78      0.86        54\n",
            "           1       0.82      0.96      0.88        55\n",
            "\n",
            "    accuracy                           0.87       109\n",
            "   macro avg       0.88      0.87      0.87       109\n",
            "weighted avg       0.88      0.87      0.87       109\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test_clean, onnx_pred_clean))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYu44hsvH3fk"
      },
      "source": [
        "#Extra: Convert the ONNX model to a PyTorch model##\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxgg1uLpL3rl",
        "outputId": "7b79da1b-b722-4d21-c236-fb0668740b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx2pytorch\n",
            "  Downloading onnx2pytorch-0.4.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▍                        | 10 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 20 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from onnx2pytorch) (0.10.0+cu111)\n",
            "Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from onnx2pytorch) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from onnx2pytorch) (1.9.0+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx2pytorch) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx2pytorch) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx2pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx2pytorch) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.9.0->onnx2pytorch) (7.1.2)\n",
            "Installing collected packages: onnx2pytorch\n",
            "Successfully installed onnx2pytorch-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx2pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Pf28FdP3M8pO",
        "outputId": "79def19d-d8b8-4b13-e7a0-28d43c9af44b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/onnx2pytorch/operations/loop.py:50: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.from_numpy(numpy_helper.to_array(tensor)),\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3c378029319e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpytorch_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onnx2pytorch/convert/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, onnx_model, batch_dim, experimental, debug, enable_pruning)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0menable_pruning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         ):\n\u001b[1;32m    128\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onnx2pytorch/convert/operations.py\u001b[0m in \u001b[0;36mconvert_operations\u001b[0;34m(onnx_graph, opset_version, batch_dim, enable_pruning)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 raise NotImplementedError(\n\u001b[0;32m--> 280\u001b[0;31m                     \u001b[0;34m\"Conversion not implemented for op_type={}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 )\n\u001b[1;32m    282\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Conversion not implemented for op_type=ReverseSequence."
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "from onnx2pytorch import ConvertModel\n",
        "\n",
        "onnx_model = onnx.load('model.onnx')\n",
        "pytorch_model = ConvertModel(onnx_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Demo2:HardwareAccess.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
